{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import sqlite3\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_webdriver(): \n",
    "    \n",
    "    # set up wen driver\n",
    "    chromedriver = r\"C:\\Users\\Anthony\\Desktop\\chromedriver.exe\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def create_soup(url):\n",
    "    ''' create bs4 object '''\n",
    "    \n",
    "    r = requests.get(url, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.94 Safari/537.36\"\n",
    "    })\n",
    "    return BeautifulSoup(r.content, \"html5lib\")\n",
    "\n",
    "\n",
    "def scrape_job_links(url):\n",
    "    \n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    # get hrefs ONLY for non- header and footer job postings \n",
    "    lst1= []\n",
    "    for div in soup.find_all('div', {'class':' row result'}):\n",
    "        links = div.find('a')['href']\n",
    "        #print(links)\n",
    "        lst1.append(links)\n",
    "\n",
    "    # last row has different class name\n",
    "    for div in soup.find_all('div', {'class':'lastRow row result'}):\n",
    "        links = div.find('a')['href']\n",
    "        #print(div)\n",
    "        lst1.append(links)\n",
    "    \n",
    "    links = ['https://www.indeed.com' + i for i in lst1]\n",
    "    return links\n",
    "\n",
    "\n",
    "def next_page_url(url):\n",
    "    ''' returns the url for the next page on an indeed job search page '''\n",
    "    \n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    # this creates a list of \"Results Page\" at bottom of screen... last url will always be next page \n",
    "    next_pages_urls = []\n",
    "    for i in soup.find_all(attrs={'class': 'pagination'}):\n",
    "        a_tags = i.find_all('a')\n",
    "        for a in a_tags:\n",
    "            next_pages = 'https://www.indeed.com' + a['href']\n",
    "            next_pages_urls.append(next_pages)\n",
    "\n",
    "    return next_pages_urls[-1]\n",
    "\n",
    "\n",
    "def filter_links(links_lst):\n",
    "    '''separates scraped indeed links based on whether they redirect you to \n",
    "       internal indeed job posts or external company website '''\n",
    "    \n",
    "    indeed_links = []\n",
    "    non_indeed_links = []\n",
    "    for i in links_lst:\n",
    "        if i.startswith('https://www.indeed.com/rc'):\n",
    "            non_indeed_links.append(i)\n",
    "            pass\n",
    "        else:\n",
    "            indeed_links.append(i)\n",
    "            \n",
    "    return indeed_links, non_indeed_links\n",
    "\n",
    "\n",
    "def bottom_scroll(webdriver):\n",
    "    ''''scroll to bottom of page--- w/ page search pages -- not individual job postings'''\n",
    "    element=webdriver.find_element_by_xpath('//*[@id=\"resultsCol\"]/div[18]')\n",
    "    return element.location_once_scrolled_into_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indeed_scraper(job_name, job_location, int_pages_to_search): \n",
    "    '''this combined everything '''\n",
    "    \n",
    "\n",
    "    driver = setup_webdriver()\n",
    "    \n",
    "    # set website to scrape and query \n",
    "    driver.get(\"https://www.indeed.com/\")\n",
    "    driver.find_element_by_id('what').clear()\n",
    "    driver.find_element_by_id('what').send_keys(job_name)\n",
    "    driver.find_element_by_id('where').clear()\n",
    "    driver.find_element_by_id('where').send_keys(job_location)\n",
    "    driver.find_element_by_id('fj').click()\n",
    "\n",
    "    \n",
    "    # x out advertisement \n",
    "    driver.find_element_by_id('prime-popover-x').click()\n",
    "    \n",
    "    # get current url and pass into bs4\n",
    "    this_url = driver.current_url\n",
    "    date_soup = create_soup(this_url)\n",
    "    \n",
    "    # sort by date \n",
    "    date_button = date_soup.find(attrs={'class': 'no-wrap'})\n",
    "    date_button2 = date_button.find('a')['href']\n",
    "    sort_by_date = 'https://www.indeed.com' + date_button2\n",
    "    \n",
    "    # pass url to driver & get current url to scrape links \n",
    "    driver.get(sort_by_date)\n",
    "    \n",
    "    # scrape em\n",
    "    all_job_links = []\n",
    "    for i in range(int(int_pages_to_search)):\n",
    "        # get current url\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "        # get job links & append to list\n",
    "        job_links = scrape_job_links(driver.current_url)\n",
    "        all_job_links.extend(job_links)\n",
    "        \n",
    "        # scroll to the bottom of screen\n",
    "        bottom_scroll(driver)\n",
    "        \n",
    "        # go to next page\n",
    "        url_next = next_page_url(driver.current_url)\n",
    "        driver.get(url_next)\n",
    "    return all_job_links\n",
    "\n",
    "# scrape text from only the indeed postings -- text stored in paragraph and list tags \n",
    "\n",
    "def job_description_to_query(url, keywords): \n",
    "    ''' job descriptions have p and li tags -- when scraped theyre list of lists --\n",
    "       flatten lists separetely, combined into 1 list, make everything lowercase &\n",
    "       remove special characters '''\n",
    "    \n",
    "    # create soup\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    # get all p tags\n",
    "    para_lst = []\n",
    "    for p in soup.find_all('p'):\n",
    "        if 'style' in p.attrs:\n",
    "            pass\n",
    "        else: \n",
    "            p_text = p.get_text()\n",
    "            para_lst.append(p_text)\n",
    "\n",
    "    # p tags is a list of lists so we need to flatten it\n",
    "    new_para_lst=[]\n",
    "    para_len = len(para_lst)\n",
    "\n",
    "    # split items in list then iterate over each list and append to new list \n",
    "    para_split = [i.split() for i in para_lst]\n",
    "    for x in range(para_len):\n",
    "        for i in para_split[x]:\n",
    "            new_para_lst.append(i)\n",
    "\n",
    "    # get all li tags \n",
    "    lists = soup.find_all('li')\n",
    "    lists_text = [i.get_text() for i in lists]        \n",
    "\n",
    "    # li tag is a list of lists so we need to flatten it \n",
    "    new_li_tag_lst = []\n",
    "    lists_len = len(lists_text)\n",
    "\n",
    "    lists_split = [i.split() for i in lists_text]\n",
    "    for x in range(lists_len):\n",
    "        for i in lists_split[x]:\n",
    "            new_li_tag_lst.append(i)\n",
    "\n",
    "    # get job title and company name \n",
    "    job_name = soup.find('b', attrs={'class': 'jobtitle'}).get_text()\n",
    "    company = soup.find('span', attrs={'class':'company'}).get_text()\n",
    "    \n",
    "    # combined cleaned lists \n",
    "    job_description = new_li_tag_lst + new_para_lst\n",
    "    \n",
    "    # format lists by remove any non-alphanum char, spaces, and make everything lowercase\n",
    "    clean_job_description = []\n",
    "    for i in job_description:\n",
    "        remove_spec_chars = re.sub('[^A-Za-z0-9]+', '', i) # removes anything thats not a letter or number \n",
    "        lowercase = remove_spec_chars.lower()\n",
    "        if lowercase: # remove spaces in list \n",
    "            clean_job_description.append(lowercase)\n",
    "    \n",
    "    #keywords = ['python', 'pandas']\n",
    "    for i in clean_job_description:\n",
    "        if any(word in i for word in keywords):\n",
    "            return url\n",
    "        \n",
    "\n",
    "def view_jobs(jobs_filtered, lst_of_keywords, sleep_time):\n",
    "    ''' given a list of ONLY INDEED JOB LINKS -- filters by keyword,\n",
    "        opens job post in new tab, gives user time to read, opens next \n",
    "        job post in new tab in same window -- all tabs that remain open \n",
    "        are the posts user deemed relevant '''\n",
    "\n",
    "    driver = setup_webdriver()\n",
    "\n",
    "    for j in jobs_filtered:\n",
    "        job_url =job_description_to_query(j, lst_of_keywords)\n",
    "        concat_url = 'window.open(\"' + job_url + '\",\"_blank\");'\n",
    "        driver.execute_script(concat_url)\n",
    "        time.sleep(int(sleep_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search indeed for job name and location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = indeed_scraper('python developer', 'New York, NY', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# separate links based on whether indeed postings or links take you to company website -- indeed posts are easier to search job description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_filt = filter_links(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take indeed links & see if keywords are in job description...\n",
    "# launch a new tab in same window for every job posting...\n",
    "# program sleeps to allow time to read job posting...\n",
    "# if user not interested in job, x it out...\n",
    "# and new posting will appear in new tab in same window\n",
    "# all leftover posts are the ones user is interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7de2f0351a96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mview_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjobs_filt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-35c9e8768d14>\u001b[0m in \u001b[0;36mview_jobs\u001b[1;34m(jobs_filtered, lst_of_keywords, sleep_time)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mconcat_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'window.open(\"'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mjob_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\",\"_blank\");'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keywords = ['python', 'training']\n",
    "\n",
    "view_jobs(jobs_filt[0], keywords, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = setup_webdriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_db_table(full_path_to_db):\n",
    "    \n",
    "    conn = sqlite3.connect(full_path_to_db)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE indeed_jobs\n",
    "        (url text, \n",
    "        company_name text, \n",
    "        job_title text)''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def post_to_db(jobs_filt, full_path_to_db):\n",
    "    \n",
    "    driver = setup_webdriver()\n",
    "    \n",
    "    create_db_table(full_path_to_db)\n",
    "    \n",
    "    conn = sqlite3.connect(full_path_to_db)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    tup_db = []\n",
    "    for url in jobs_filt:\n",
    "        driver.get(url)\n",
    "        soup = create_soup(driver.current_url)\n",
    "        job_name = soup.find('b', attrs={'class': 'jobtitle'}).get_text()\n",
    "        company = soup.find('span', attrs={'class':'company'}).get_text()\n",
    "        tup = job_name, company, driver.current_url\n",
    "        tup_db.append(tup)\n",
    "        \n",
    "        c.execute(\"insert into indeed_jobs (url, company_name, job_title) values (?, ?, ?)\",\n",
    "            (driver.current_url, company, job_name))\n",
    "        conn.commit()\n",
    "    #conn.close()\n",
    "        \n",
    "    return tup_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ruby on Rails Engineer',\n",
       "  'Intelletec',\n",
       "  'https://www.indeed.com/cmp/Intelletec/jobs/Ruby-Rail-Engineer-7d5e112d9ae5fe2b'),\n",
       " ('OOP - Python',\n",
       "  'IITS',\n",
       "  'https://www.indeed.com/cmp/IITS/jobs/Oop-754be9f354c37f91'),\n",
       " ('Web Architect',\n",
       "  'Access Staffing',\n",
       "  'https://www.indeed.com/cmp/Access-Staffing-LLC/jobs/Web-Architect-9c07bc52cbe296f8'),\n",
       " ('Scala Developer',\n",
       "  'Ascon Soft',\n",
       "  'https://www.indeed.com/cmp/Ascon-Soft/jobs/Scala-Developer-e1f6d27e50cdacd0'),\n",
       " ('ETL Architect',\n",
       "  'Afactory HUB, Inc',\n",
       "  'https://www.indeed.com/cmp/Afactory-HUB-Inc/jobs/ETL-Architect-abafff36e03d6133'),\n",
       " ('DevOps',\n",
       "  'Alagen',\n",
       "  'https://www.indeed.com/cmp/Alagen/jobs/Devop-af642c1243af04f4'),\n",
       " ('Java Developer',\n",
       "  'Strivector',\n",
       "  'https://www.indeed.com/cmp/Strivector/jobs/Java-Developer-3364e453fc19fe80'),\n",
       " ('Java Developer with Kafka',\n",
       "  'Amiga Informatics',\n",
       "  'https://www.indeed.com/cmp/Amiga-Informatics/jobs/Java-Developer-Kafka-abef2b4680f585c3'),\n",
       " ('Lead Systems Analyst/Programmer',\n",
       "  'The Lamont-Doherty Earth Observatory of Columbia University',\n",
       "  'https://www.indeed.com/cmp/The-Lamont--Doherty-Earth-Observatory-of/jobs/Lead-System-Analyst-Programmer-d0b1a31fedf072b8'),\n",
       " ('Lead Systems Analyst/Programmer',\n",
       "  'The Lamont-Doherty Earth Observatory of Columbia University',\n",
       "  'https://www.indeed.com/cmp/The-Lamont--Doherty-Earth-Observatory-of/jobs/Lead-System-Analyst-Programmer-d0b1a31fedf072b8'),\n",
       " ('Lead DevOps Engineer',\n",
       "  'CA-One Tech Cloud Inc.',\n",
       "  'https://www.indeed.com/cmp/CA--One-Tech-Cloud-Inc./jobs/Lead-Devop-Engineer-8be511513fa2ef69'),\n",
       " ('Python Developer',\n",
       "  'SANS Consulting Services, Inc',\n",
       "  'https://www.indeed.com/cmp/SANS-Consulting-Services,-Inc/jobs/Python-Developer-2720bbb2db15234f'),\n",
       " ('Python Software Engineer',\n",
       "  'SANS Consulting Services, Inc',\n",
       "  'https://www.indeed.com/cmp/SANS-Consulting-Services,-Inc/jobs/Python-Software-Engineer-9325c06b2d8a8a59')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path = r'C:\\Users\\Anthony\\Documents\\db\\indeed8.sqlite'\n",
    "\n",
    "post_to_db(jobs_filt[0], db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.indeed.com/company/Intelletec/jobs/Ruby-Rail-Engineer-7d5e112d9ae5fe2b?fccid=c72a0a2653e9c59d',\n",
       " 'https://www.indeed.com/company/IITS/jobs/Oop-754be9f354c37f91?fccid=8d387370c9d53b88',\n",
       " 'https://www.indeed.com/company/Access-Staffing-LLC/jobs/Web-Architect-9c07bc52cbe296f8?fccid=28912ef34bc6ef48',\n",
       " 'https://www.indeed.com/company/Ascon-Soft/jobs/Scala-Developer-e1f6d27e50cdacd0?fccid=cf817a4f78ecb56a',\n",
       " 'https://www.indeed.com/company/Afactory-HUB-Inc/jobs/ETL-Architect-abafff36e03d6133?fccid=20075c7f8d5406e8',\n",
       " 'https://www.indeed.com/company/Alagen/jobs/Devop-af642c1243af04f4?fccid=8762a3e16717dc82',\n",
       " 'https://www.indeed.com/company/Strivector/jobs/Java-Developer-3364e453fc19fe80?fccid=9ed4d98a4f5cad27',\n",
       " 'https://www.indeed.com/company/Amiga-Informatics/jobs/Java-Developer-Kafka-abef2b4680f585c3?fccid=531057b22748b190',\n",
       " 'https://www.indeed.com/company/The-Lamont--Doherty-Earth-Observatory-of/jobs/Lead-System-Analyst-Programmer-d0b1a31fedf072b8?fccid=6f303f69f85262e0',\n",
       " 'https://www.indeed.com/company/The-Lamont--Doherty-Earth-Observatory-of/jobs/Lead-System-Analyst-Programmer-d0b1a31fedf072b8?fccid=6f303f69f85262e0',\n",
       " 'https://www.indeed.com/company/CA--One-Tech-Cloud-Inc./jobs/Lead-Devop-Engineer-8be511513fa2ef69?fccid=3902f8b39489930b',\n",
       " 'https://www.indeed.com/company/SANS-Consulting-Services,-Inc/jobs/Python-Developer-2720bbb2db15234f?fccid=5d90741236d0e995',\n",
       " 'https://www.indeed.com/company/SANS-Consulting-Services,-Inc/jobs/Python-Software-Engineer-9325c06b2d8a8a59?fccid=5d90741236d0e995']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_filt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_db_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Documents\\db\n"
     ]
    }
   ],
   "source": [
    "cd db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('indeed4.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE indeed_jobs\n",
    "    (url text, \n",
    "    company_name text, \n",
    "    job_title text)''')\n",
    "\n",
    "c.execute(\"insert into indeed_jobs (url, company_name, job_title) values (?, ?, ?)\",\n",
    "            (current_url, company, job_name))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scroll(webdriver):\n",
    "    \n",
    "    # scroll to bottom of page\n",
    "    element=webdriver.find_element_by_xpath('//*[@id=\"resultsCol\"]/div[18]')\n",
    "    return element.location_once_scrolled_into_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_scrolling():\n",
    "\n",
    "    driver= setup_webdriver()\n",
    "    \n",
    "    # get specifics \n",
    "    driver.get(\"https://www.indeed.com/\")\n",
    "    driver.find_element_by_id('what').clear()\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id('what').send_keys('python developer')\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id('where').clear()\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id('where').send_keys('New York, NY')\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id('fj').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.find_element_by_id('prime-popover-x').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # scrape jobs from that url \n",
    "    job_links = scrape_job_links(driver.current_url)\n",
    "    # filter to only indeed jobs\n",
    "    jobs_filt = filter_links(job_links)\n",
    "    \n",
    "    # start at a good xpath and count up div tags that appear in every page to 'smooth' scroll\n",
    "    count = 0\n",
    "    for i in range(2):\n",
    "        for j in jobs_filt:\n",
    "            driver.get(j)\n",
    "            time.sleep(2)\n",
    "            count+=1\n",
    "            #print(count, j)\n",
    "            str_ = str(count)\n",
    "\n",
    "            #concat_div = '//*[@id=\"resultsCol\"]/div[' + str_ + ']'\n",
    "            try: \n",
    "                concat_div = '//*[@id=\"job-content\"]/tbody/tr/td[1]/table/tbody/tr/td/div[2]/div[2]/div[' + str_ + ']'\n",
    "                #concat_div = '//*[@id=\"job-content\"]/tbody/tr/td[1]/table/tbody/tr/td/div[2]/div[' + str_ + ']'\n",
    "                element=driver.find_element_by_xpath(concat_div)\n",
    "                element.location_once_scrolled_into_view\n",
    "                time.sleep(2)\n",
    "                driver.get(j)\n",
    "                print(j)\n",
    "            except:\n",
    "                browser.get(j)\n",
    "                print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/company/NYTP/jobs/Python-Engineer-8578a5b36c166821?fccid=ccff84ac3dd19bb9\n",
      "https://www.indeed.com/company/RAPS-consulting/jobs/Senior-Python-Developer-21d5e8cd39ab722f?fccid=9b7a3860892e2fcd\n",
      "https://www.indeed.com/company/Kasisto/jobs/Front-End-Software-Engineer-e8ee0083bfbe3831?fccid=521ca7ccc49e32d5\n",
      "https://www.indeed.com/company/Chase-Dream-LLC/jobs/Software-Engineer-Python-98563184e467ab84?fccid=ed0eadb761b45e00\n",
      "https://www.indeed.com/company/LIS-Solutions/jobs/Python-Developer-a424fc091c993864?fccid=58aef85eed32eea8\n",
      "https://www.indeed.com/company/BlindData/jobs/Software-Engineer-010d7c76f5d1fa19?fccid=55962a85574fa94f\n",
      "https://www.indeed.com/company/NYTP/jobs/Python-Engineer-8578a5b36c166821?fccid=ccff84ac3dd19bb9\n",
      "https://www.indeed.com/company/RAPS-consulting/jobs/Senior-Python-Developer-21d5e8cd39ab722f?fccid=9b7a3860892e2fcd\n",
      "https://www.indeed.com/company/Kasisto/jobs/Front-End-Software-Engineer-e8ee0083bfbe3831?fccid=521ca7ccc49e32d5\n",
      "https://www.indeed.com/company/Chase-Dream-LLC/jobs/Software-Engineer-Python-98563184e467ab84?fccid=ed0eadb761b45e00\n",
      "https://www.indeed.com/company/LIS-Solutions/jobs/Python-Developer-a424fc091c993864?fccid=58aef85eed32eea8\n",
      "https://www.indeed.com/company/BlindData/jobs/Software-Engineer-010d7c76f5d1fa19?fccid=55962a85574fa94f\n"
     ]
    }
   ],
   "source": [
    "smooth_scrolling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/company/Intelletec/jobs/Ruby-Rail-Engineer-7d5e112d9ae5fe2b?fccid=c72a0a2653e9c59d\n",
      "https://www.indeed.com/company/Alagen/jobs/Devop-af642c1243af04f4?fccid=8762a3e16717dc82\n",
      "https://www.indeed.com/company/Ascon-Soft/jobs/Scala-Developer-e1f6d27e50cdacd0?fccid=cf817a4f78ecb56a\n",
      "https://www.indeed.com/company/Afactory-HUB-Inc/jobs/ETL-Architect-abafff36e03d6133?fccid=20075c7f8d5406e8\n",
      "https://www.indeed.com/company/Strivector/jobs/Java-Developer-3364e453fc19fe80?fccid=9ed4d98a4f5cad27\n",
      "https://www.indeed.com/company/Amiga-Informatics/jobs/Java-Developer-Kafka-abef2b4680f585c3?fccid=531057b22748b190\n",
      "!!!! too many years https://www.indeed.com/company/The-Lamont--Doherty-Earth-Observatory-of/jobs/Lead-System-Analyst-Programmer-d0b1a31fedf072b8?fccid=6f303f69f85262e0\n",
      "https://www.indeed.com/company/CA--One-Tech-Cloud-Inc./jobs/Lead-Devop-Engineer-8be511513fa2ef69?fccid=3902f8b39489930b\n",
      "https://www.indeed.com/company/Lorven-Technologies-Inc/jobs/Salesforce-Consultant-Net-961f7cb2ea9edf1d?fccid=2fa42ae8efdf5515\n",
      "!!!! too many years https://www.indeed.com/company/TalentHub-Worldwide,-Inc./jobs/Mobile-Operation-Manager-1032b5a82723a94c?fccid=5a3a467f20e42a1b\n",
      "https://www.indeed.com/company/SANS-Consulting-Services,-Inc/jobs/Python-Developer-2720bbb2db15234f?fccid=5d90741236d0e995\n",
      "https://www.indeed.com/company/SANS-Consulting-Services,-Inc/jobs/Python-Software-Engineer-9325c06b2d8a8a59?fccid=5d90741236d0e995\n",
      "https://www.indeed.com/company/Intelletec/jobs/Ruby-Rail-Developer-1891b0580de7911f?fccid=c72a0a2653e9c59d\n",
      "https://www.indeed.com/company/Boyle-Software/jobs/Java-ceff358a761df335?fccid=18ef4c3a4d486e61\n",
      "https://www.indeed.com/company/Amiga-Informatics/jobs/Java-Automation-Developer-4e3e59ce19d44c0e?fccid=531057b22748b190\n",
      "https://www.indeed.com/company/GCS-Recruitment-Specialists/jobs/Senior-Ruby-Developer-61122061f0aaffae?fccid=b1aff4bf9087a3db\n",
      "https://www.indeed.com/company/Ana--Data-Consulting/jobs/Java-ddb37a6164de16ae?fccid=a74a727b18f13004\n",
      "https://www.indeed.com/company/NJF-Search/jobs/Senior-Java-Developer-adb17fd4c4430dff?fccid=b83cacb11bfd1dc9\n",
      "https://www.indeed.com/company/Lorven-Technologies-Inc/jobs/Salesforce-Developer-Net-550cd664a237973f?fccid=fd51a90e8da2930d\n",
      "https://www.indeed.com/company/Marchon-Partners/jobs/Python-Developer-1781609570a6f31c?fccid=2dadb8e1e2d6757e\n",
      "https://www.indeed.com/company/NADAP/jobs/Coldfusion-Database-Developer-5e42ec7e3724b8be?fccid=d65693b144321973\n",
      "https://www.indeed.com/company/Scalene-Solutions/jobs/Perl-or-Python-Developer-ab51da30f5019220?fccid=c95e28c025f87886\n",
      "https://www.indeed.com/company/Prestige-Staffing/jobs/Front-End-Developer-b23efc66f1304a2e?fccid=e13d96ed10f55761\n",
      "https://www.indeed.com/company/Technovision,-Inc./jobs/-2f7de2a0bba68ddb?fccid=36b8de23dad08013\n"
     ]
    }
   ],
   "source": [
    "keywords = ['python', 'training']\n",
    "\n",
    "skip_keywoords = ['3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "for url in jobs_filt:\n",
    "    job_desc =job_description_to_query(url)\n",
    "    if any(word in job_desc for word in keywords):\n",
    "        print(url)\n",
    "    elif any(s in job_desc for s in skip_keywoords):\n",
    "        print('!!!! too many years', url)\n",
    "        pass\n",
    "    else:\n",
    "        print('!!!!!bad', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver=setup_webdriver()\n",
    "driver.get(jobs[0])\n",
    "\n",
    "\n",
    "lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match=False\n",
    "while(match==False):\n",
    "        lastCount = lenOfPage\n",
    "        time.sleep(3)\n",
    "        lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "        if lastCount==lenOfPage:\n",
    "            match=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
